{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnYechanJo/AI-Study/blob/main/colab/Week8_4_MLP_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rt63f8XbTrgb"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "dataset = datasets.load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "X = torch.tensor(dataset.data, dtype=torch.float32)\n",
        "y = torch.tensor(dataset.target)"
      ],
      "metadata": {
        "id": "3o__mb9CUZoU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, hidden_units):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(4, hidden_units)\n",
        "    self.fc2 = nn.Linear(hidden_units, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "lsatWxd6T7vH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(5)"
      ],
      "metadata": {
        "id": "78oXC-F5LiqG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "TOZmBIh3UnT6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion):\n",
        "  for epoch in range(100):\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = criterion(y_pred, y)\n",
        "    print(f\"Epoch: {epoch} / Loss: {loss}\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "train(model, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTngoWE1Vsxi",
        "outputId": "89f627fd-492b-4217-c5c9-ed4007aae9a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 / Loss: 0.06263065338134766\n",
            "Epoch: 1 / Loss: 0.06254389882087708\n",
            "Epoch: 2 / Loss: 0.06245840713381767\n",
            "Epoch: 3 / Loss: 0.06237364932894707\n",
            "Epoch: 4 / Loss: 0.06228974089026451\n",
            "Epoch: 5 / Loss: 0.06220727413892746\n",
            "Epoch: 6 / Loss: 0.06212545931339264\n",
            "Epoch: 7 / Loss: 0.0620439350605011\n",
            "Epoch: 8 / Loss: 0.06196356564760208\n",
            "Epoch: 9 / Loss: 0.061883699148893356\n",
            "Epoch: 10 / Loss: 0.061803996562957764\n",
            "Epoch: 11 / Loss: 0.06172513961791992\n",
            "Epoch: 12 / Loss: 0.061646703630685806\n",
            "Epoch: 13 / Loss: 0.06156919524073601\n",
            "Epoch: 14 / Loss: 0.06149224564433098\n",
            "Epoch: 15 / Loss: 0.061416346579790115\n",
            "Epoch: 16 / Loss: 0.061341043561697006\n",
            "Epoch: 17 / Loss: 0.0612662248313427\n",
            "Epoch: 18 / Loss: 0.0611921101808548\n",
            "Epoch: 19 / Loss: 0.06111907213926315\n",
            "Epoch: 20 / Loss: 0.06104660779237747\n",
            "Epoch: 21 / Loss: 0.06097503751516342\n",
            "Epoch: 22 / Loss: 0.06090318039059639\n",
            "Epoch: 23 / Loss: 0.060830630362033844\n",
            "Epoch: 24 / Loss: 0.06075972691178322\n",
            "Epoch: 25 / Loss: 0.060691166669130325\n",
            "Epoch: 26 / Loss: 0.06062270328402519\n",
            "Epoch: 27 / Loss: 0.06055457517504692\n",
            "Epoch: 28 / Loss: 0.06048710644245148\n",
            "Epoch: 29 / Loss: 0.060420647263526917\n",
            "Epoch: 30 / Loss: 0.06035468354821205\n",
            "Epoch: 31 / Loss: 0.060289014130830765\n",
            "Epoch: 32 / Loss: 0.060223568230867386\n",
            "Epoch: 33 / Loss: 0.06015878543257713\n",
            "Epoch: 34 / Loss: 0.060095299035310745\n",
            "Epoch: 35 / Loss: 0.06003258377313614\n",
            "Epoch: 36 / Loss: 0.05996972322463989\n",
            "Epoch: 37 / Loss: 0.059907618910074234\n",
            "Epoch: 38 / Loss: 0.059846337884664536\n",
            "Epoch: 39 / Loss: 0.05978572368621826\n",
            "Epoch: 40 / Loss: 0.059725772589445114\n",
            "Epoch: 41 / Loss: 0.05966608226299286\n",
            "Epoch: 42 / Loss: 0.05960662662982941\n",
            "Epoch: 43 / Loss: 0.05954771116375923\n",
            "Epoch: 44 / Loss: 0.059489402920007706\n",
            "Epoch: 45 / Loss: 0.05943157896399498\n",
            "Epoch: 46 / Loss: 0.05937408283352852\n",
            "Epoch: 47 / Loss: 0.05931713804602623\n",
            "Epoch: 48 / Loss: 0.059260763227939606\n",
            "Epoch: 49 / Loss: 0.059204209595918655\n",
            "Epoch: 50 / Loss: 0.05914909392595291\n",
            "Epoch: 51 / Loss: 0.059093717485666275\n",
            "Epoch: 52 / Loss: 0.05903923511505127\n",
            "Epoch: 53 / Loss: 0.05898482725024223\n",
            "Epoch: 54 / Loss: 0.05893077328801155\n",
            "Epoch: 55 / Loss: 0.05887706205248833\n",
            "Epoch: 56 / Loss: 0.058823782950639725\n",
            "Epoch: 57 / Loss: 0.05877102538943291\n",
            "Epoch: 58 / Loss: 0.058718591928482056\n",
            "Epoch: 59 / Loss: 0.05866631865501404\n",
            "Epoch: 60 / Loss: 0.05861459672451019\n",
            "Epoch: 61 / Loss: 0.058562979102134705\n",
            "Epoch: 62 / Loss: 0.058512236922979355\n",
            "Epoch: 63 / Loss: 0.05846147611737251\n",
            "Epoch: 64 / Loss: 0.058410994708538055\n",
            "Epoch: 65 / Loss: 0.05836063250899315\n",
            "Epoch: 66 / Loss: 0.05831104889512062\n",
            "Epoch: 67 / Loss: 0.05826131999492645\n",
            "Epoch: 68 / Loss: 0.05821237713098526\n",
            "Epoch: 69 / Loss: 0.05816330015659332\n",
            "Epoch: 70 / Loss: 0.05811465531587601\n",
            "Epoch: 71 / Loss: 0.05806631222367287\n",
            "Epoch: 72 / Loss: 0.058017633855342865\n",
            "Epoch: 73 / Loss: 0.05796973407268524\n",
            "Epoch: 74 / Loss: 0.05792221054434776\n",
            "Epoch: 75 / Loss: 0.057874392718076706\n",
            "Epoch: 76 / Loss: 0.05782786011695862\n",
            "Epoch: 77 / Loss: 0.05778033658862114\n",
            "Epoch: 78 / Loss: 0.057733744382858276\n",
            "Epoch: 79 / Loss: 0.057687532156705856\n",
            "Epoch: 80 / Loss: 0.05764123424887657\n",
            "Epoch: 81 / Loss: 0.05759574845433235\n",
            "Epoch: 82 / Loss: 0.057550594210624695\n",
            "Epoch: 83 / Loss: 0.05750346556305885\n",
            "Epoch: 84 / Loss: 0.05745784193277359\n",
            "Epoch: 85 / Loss: 0.05741245299577713\n",
            "Epoch: 86 / Loss: 0.05736791715025902\n",
            "Epoch: 87 / Loss: 0.05732254683971405\n",
            "Epoch: 88 / Loss: 0.057278428226709366\n",
            "Epoch: 89 / Loss: 0.05723423510789871\n",
            "Epoch: 90 / Loss: 0.05719003826379776\n",
            "Epoch: 91 / Loss: 0.05714656785130501\n",
            "Epoch: 92 / Loss: 0.05710222199559212\n",
            "Epoch: 93 / Loss: 0.05705853924155235\n",
            "Epoch: 94 / Loss: 0.057015545666217804\n",
            "Epoch: 95 / Loss: 0.05697242170572281\n",
            "Epoch: 96 / Loss: 0.05692993849515915\n",
            "Epoch: 97 / Loss: 0.056887436658144\n",
            "Epoch: 98 / Loss: 0.05684541165828705\n",
            "Epoch: 99 / Loss: 0.05680297687649727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(100)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "train(model, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wk2_ahIVJfz",
        "outputId": "0b3319a7-2ecd-4655-88b6-b0f7b1ec9372"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 / Loss: 1.5135016441345215\n",
            "Epoch: 1 / Loss: 11.372712135314941\n",
            "Epoch: 2 / Loss: 9.700274467468262\n",
            "Epoch: 3 / Loss: 9.667405128479004\n",
            "Epoch: 4 / Loss: 1.1444183588027954\n",
            "Epoch: 5 / Loss: 1.2374658584594727\n",
            "Epoch: 6 / Loss: 0.5838534235954285\n",
            "Epoch: 7 / Loss: 0.5757404565811157\n",
            "Epoch: 8 / Loss: 0.5171756148338318\n",
            "Epoch: 9 / Loss: 0.5044518113136292\n",
            "Epoch: 10 / Loss: 0.4672192931175232\n",
            "Epoch: 11 / Loss: 0.4567028880119324\n",
            "Epoch: 12 / Loss: 0.4328063428401947\n",
            "Epoch: 13 / Loss: 0.4251098036766052\n",
            "Epoch: 14 / Loss: 0.4085700511932373\n",
            "Epoch: 15 / Loss: 0.40414372086524963\n",
            "Epoch: 16 / Loss: 0.3918748199939728\n",
            "Epoch: 17 / Loss: 0.39084556698799133\n",
            "Epoch: 18 / Loss: 0.3811367154121399\n",
            "Epoch: 19 / Loss: 0.38347336649894714\n",
            "Epoch: 20 / Loss: 0.3752053380012512\n",
            "Epoch: 21 / Loss: 0.3813750147819519\n",
            "Epoch: 22 / Loss: 0.37253329157829285\n",
            "Epoch: 23 / Loss: 0.38208556175231934\n",
            "Epoch: 24 / Loss: 0.37059611082077026\n",
            "Epoch: 25 / Loss: 0.38255786895751953\n",
            "Epoch: 26 / Loss: 0.36687806248664856\n",
            "Epoch: 27 / Loss: 0.37894219160079956\n",
            "Epoch: 28 / Loss: 0.3598605990409851\n",
            "Epoch: 29 / Loss: 0.3712255358695984\n",
            "Epoch: 30 / Loss: 0.3508615493774414\n",
            "Epoch: 31 / Loss: 0.3612891137599945\n",
            "Epoch: 32 / Loss: 0.34125545620918274\n",
            "Epoch: 33 / Loss: 0.3511508107185364\n",
            "Epoch: 34 / Loss: 0.3322082757949829\n",
            "Epoch: 35 / Loss: 0.34261924028396606\n",
            "Epoch: 36 / Loss: 0.3249751627445221\n",
            "Epoch: 37 / Loss: 0.33644434809684753\n",
            "Epoch: 38 / Loss: 0.31950515508651733\n",
            "Epoch: 39 / Loss: 0.3321828246116638\n",
            "Epoch: 40 / Loss: 0.31543198227882385\n",
            "Epoch: 41 / Loss: 0.3293832838535309\n",
            "Epoch: 42 / Loss: 0.3120797574520111\n",
            "Epoch: 43 / Loss: 0.32711124420166016\n",
            "Epoch: 44 / Loss: 0.3090013265609741\n",
            "Epoch: 45 / Loss: 0.32496997714042664\n",
            "Epoch: 46 / Loss: 0.30559876561164856\n",
            "Epoch: 47 / Loss: 0.32198619842529297\n",
            "Epoch: 48 / Loss: 0.30214041471481323\n",
            "Epoch: 49 / Loss: 0.31879720091819763\n",
            "Epoch: 50 / Loss: 0.2984957695007324\n",
            "Epoch: 51 / Loss: 0.3156736493110657\n",
            "Epoch: 52 / Loss: 0.29461905360221863\n",
            "Epoch: 53 / Loss: 0.3117467164993286\n",
            "Epoch: 54 / Loss: 0.2908885180950165\n",
            "Epoch: 55 / Loss: 0.3083308935165405\n",
            "Epoch: 56 / Loss: 0.28733882308006287\n",
            "Epoch: 57 / Loss: 0.30509763956069946\n",
            "Epoch: 58 / Loss: 0.28407174348831177\n",
            "Epoch: 59 / Loss: 0.30241960287094116\n",
            "Epoch: 60 / Loss: 0.2815089523792267\n",
            "Epoch: 61 / Loss: 0.30026158690452576\n",
            "Epoch: 62 / Loss: 0.2786807119846344\n",
            "Epoch: 63 / Loss: 0.2977871894836426\n",
            "Epoch: 64 / Loss: 0.27590134739875793\n",
            "Epoch: 65 / Loss: 0.29547929763793945\n",
            "Epoch: 66 / Loss: 0.27341601252555847\n",
            "Epoch: 67 / Loss: 0.2932276427745819\n",
            "Epoch: 68 / Loss: 0.27111104130744934\n",
            "Epoch: 69 / Loss: 0.2908991277217865\n",
            "Epoch: 70 / Loss: 0.2680460214614868\n",
            "Epoch: 71 / Loss: 0.2878245413303375\n",
            "Epoch: 72 / Loss: 0.2647789418697357\n",
            "Epoch: 73 / Loss: 0.28452298045158386\n",
            "Epoch: 74 / Loss: 0.26172497868537903\n",
            "Epoch: 75 / Loss: 0.2813286781311035\n",
            "Epoch: 76 / Loss: 0.2578582167625427\n",
            "Epoch: 77 / Loss: 0.27688920497894287\n",
            "Epoch: 78 / Loss: 0.2536683678627014\n",
            "Epoch: 79 / Loss: 0.27237987518310547\n",
            "Epoch: 80 / Loss: 0.24991676211357117\n",
            "Epoch: 81 / Loss: 0.26855772733688354\n",
            "Epoch: 82 / Loss: 0.24663373827934265\n",
            "Epoch: 83 / Loss: 0.2654733657836914\n",
            "Epoch: 84 / Loss: 0.2439723163843155\n",
            "Epoch: 85 / Loss: 0.2631620764732361\n",
            "Epoch: 86 / Loss: 0.24176569283008575\n",
            "Epoch: 87 / Loss: 0.26135534048080444\n",
            "Epoch: 88 / Loss: 0.24010320007801056\n",
            "Epoch: 89 / Loss: 0.2601137161254883\n",
            "Epoch: 90 / Loss: 0.23906290531158447\n",
            "Epoch: 91 / Loss: 0.2596537172794342\n",
            "Epoch: 92 / Loss: 0.23763002455234528\n",
            "Epoch: 93 / Loss: 0.25838541984558105\n",
            "Epoch: 94 / Loss: 0.23614026606082916\n",
            "Epoch: 95 / Loss: 0.25709769129753113\n",
            "Epoch: 96 / Loss: 0.2347526252269745\n",
            "Epoch: 97 / Loss: 0.2558375298976898\n",
            "Epoch: 98 / Loss: 0.23264802992343903\n",
            "Epoch: 99 / Loss: 0.25348353385925293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(1000)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "train(model, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE7-CEbpV3pv",
        "outputId": "33f592e9-6a2d-43b0-9cc8-889ec8dfcb75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 / Loss: 0.9595569968223572\n",
            "Epoch: 1 / Loss: 44.764808654785156\n",
            "Epoch: 2 / Loss: 50.39900588989258\n",
            "Epoch: 3 / Loss: 3.073612689971924\n",
            "Epoch: 4 / Loss: 30.819414138793945\n",
            "Epoch: 5 / Loss: 31.867321014404297\n",
            "Epoch: 6 / Loss: 14.025121688842773\n",
            "Epoch: 7 / Loss: 0.9435670971870422\n",
            "Epoch: 8 / Loss: 7.9251813888549805\n",
            "Epoch: 9 / Loss: 2.761582136154175\n",
            "Epoch: 10 / Loss: 3.2367944717407227\n",
            "Epoch: 11 / Loss: 3.0940370559692383\n",
            "Epoch: 12 / Loss: 0.7135511040687561\n",
            "Epoch: 13 / Loss: 1.986608862876892\n",
            "Epoch: 14 / Loss: 0.5950701832771301\n",
            "Epoch: 15 / Loss: 0.9388465285301208\n",
            "Epoch: 16 / Loss: 0.42232072353363037\n",
            "Epoch: 17 / Loss: 0.4101221263408661\n",
            "Epoch: 18 / Loss: 0.14878301322460175\n",
            "Epoch: 19 / Loss: 0.11238895356655121\n",
            "Epoch: 20 / Loss: 0.08602980524301529\n",
            "Epoch: 21 / Loss: 0.08208215981721878\n",
            "Epoch: 22 / Loss: 0.08011328428983688\n",
            "Epoch: 23 / Loss: 0.07895355671644211\n",
            "Epoch: 24 / Loss: 0.0780600905418396\n",
            "Epoch: 25 / Loss: 0.07731470465660095\n",
            "Epoch: 26 / Loss: 0.07666394859552383\n",
            "Epoch: 27 / Loss: 0.0760832130908966\n",
            "Epoch: 28 / Loss: 0.07555454224348068\n",
            "Epoch: 29 / Loss: 0.07506995648145676\n",
            "Epoch: 30 / Loss: 0.07462232559919357\n",
            "Epoch: 31 / Loss: 0.07420448958873749\n",
            "Epoch: 32 / Loss: 0.07381293922662735\n",
            "Epoch: 33 / Loss: 0.07344502210617065\n",
            "Epoch: 34 / Loss: 0.07309598475694656\n",
            "Epoch: 35 / Loss: 0.07276403158903122\n",
            "Epoch: 36 / Loss: 0.07244615256786346\n",
            "Epoch: 37 / Loss: 0.07214131951332092\n",
            "Epoch: 38 / Loss: 0.07184217125177383\n",
            "Epoch: 39 / Loss: 0.07155930250883102\n",
            "Epoch: 40 / Loss: 0.07128793001174927\n",
            "Epoch: 41 / Loss: 0.07102527469396591\n",
            "Epoch: 42 / Loss: 0.07077115029096603\n",
            "Epoch: 43 / Loss: 0.07052499800920486\n",
            "Epoch: 44 / Loss: 0.07028798758983612\n",
            "Epoch: 45 / Loss: 0.070058673620224\n",
            "Epoch: 46 / Loss: 0.06983526796102524\n",
            "Epoch: 47 / Loss: 0.06961768865585327\n",
            "Epoch: 48 / Loss: 0.06940538436174393\n",
            "Epoch: 49 / Loss: 0.0691966786980629\n",
            "Epoch: 50 / Loss: 0.06899368762969971\n",
            "Epoch: 51 / Loss: 0.06879965215921402\n",
            "Epoch: 52 / Loss: 0.06861129403114319\n",
            "Epoch: 53 / Loss: 0.06842728704214096\n",
            "Epoch: 54 / Loss: 0.06824727356433868\n",
            "Epoch: 55 / Loss: 0.06807004660367966\n",
            "Epoch: 56 / Loss: 0.06789704412221909\n",
            "Epoch: 57 / Loss: 0.06772729754447937\n",
            "Epoch: 58 / Loss: 0.06756125390529633\n",
            "Epoch: 59 / Loss: 0.06739823520183563\n",
            "Epoch: 60 / Loss: 0.06723878532648087\n",
            "Epoch: 61 / Loss: 0.06708290427923203\n",
            "Epoch: 62 / Loss: 0.06692970544099808\n",
            "Epoch: 63 / Loss: 0.06677961349487305\n",
            "Epoch: 64 / Loss: 0.06663229316473007\n",
            "Epoch: 65 / Loss: 0.0664873793721199\n",
            "Epoch: 66 / Loss: 0.06634505838155746\n",
            "Epoch: 67 / Loss: 0.0662047415971756\n",
            "Epoch: 68 / Loss: 0.06606791168451309\n",
            "Epoch: 69 / Loss: 0.06593234091997147\n",
            "Epoch: 70 / Loss: 0.0657990425825119\n",
            "Epoch: 71 / Loss: 0.06566780060529709\n",
            "Epoch: 72 / Loss: 0.06553918868303299\n",
            "Epoch: 73 / Loss: 0.06541239470243454\n",
            "Epoch: 74 / Loss: 0.06528779119253159\n",
            "Epoch: 75 / Loss: 0.06516570597887039\n",
            "Epoch: 76 / Loss: 0.06504587084054947\n",
            "Epoch: 77 / Loss: 0.06492764502763748\n",
            "Epoch: 78 / Loss: 0.06481166929006577\n",
            "Epoch: 79 / Loss: 0.06469719856977463\n",
            "Epoch: 80 / Loss: 0.06458427757024765\n",
            "Epoch: 81 / Loss: 0.06447335332632065\n",
            "Epoch: 82 / Loss: 0.06436416506767273\n",
            "Epoch: 83 / Loss: 0.06425709277391434\n",
            "Epoch: 84 / Loss: 0.06415142863988876\n",
            "Epoch: 85 / Loss: 0.06404749304056168\n",
            "Epoch: 86 / Loss: 0.06394478678703308\n",
            "Epoch: 87 / Loss: 0.06384418159723282\n",
            "Epoch: 88 / Loss: 0.0637444406747818\n",
            "Epoch: 89 / Loss: 0.06364625692367554\n",
            "Epoch: 90 / Loss: 0.06354877352714539\n",
            "Epoch: 91 / Loss: 0.06345250457525253\n",
            "Epoch: 92 / Loss: 0.06335765868425369\n",
            "Epoch: 93 / Loss: 0.06326356530189514\n",
            "Epoch: 94 / Loss: 0.06317026913166046\n",
            "Epoch: 95 / Loss: 0.06307769566774368\n",
            "Epoch: 96 / Loss: 0.06298626214265823\n",
            "Epoch: 97 / Loss: 0.0628959909081459\n",
            "Epoch: 98 / Loss: 0.06280656158924103\n",
            "Epoch: 99 / Loss: 0.06271793693304062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "68HPPQ3rWIi0"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}